{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  \n",
    "\n",
    "**!Recommend to view the notebook on Github!**  \n",
    "Github Link : https://github.com/heartcored98/CH485_AI_Chemistry/blob/master/Practice2_Tox21_SVM/Assignment2_Tox21_SVM.ipynb\n",
    "\n",
    "In this jupyter notebook, a toxicity of the molecular will be classified with the **Multi Layer Perceptron(MLP)** on **Tox21** dataset.  \n",
    "**Tox21** dataset consists of molecular smile strings as inputs and binary labels as outputs.  \n",
    "\n",
    "This notebook has following features  \n",
    "- Convert smile string into _Morgan Fingerprints_(error handling enabled) with **RDkit**  \n",
    "- Synthesis _insufficient class data_ by **imblearn SMOTE** algorithm in order to handle class imbalanced dataset \n",
    "- Support data spliting for _K-fold vallidation_ process easily\n",
    "- Train and test multiple experiments of various hyperparameter sets _in parallel_ with **multiprocessing Pool**\n",
    "- Manage experiment and model _hyperparameters_ at once with **argparse**  \n",
    "- _Visualize_ experiment results with minimal changes of codes with **seaborn** and **pandas Dataframe**  \n",
    "\n",
    "Throughout the notebook, there are **5** experiments with following investigation purpose.  \n",
    "Note that **classification performance** includes _binary classification accuracy_ and _roc-auc metric._  \n",
    "1. Influence of the **fingerprint dimension** toward **classification performance**.  \n",
    "2. Influence of the **kernel** in the SVC model toward **classification performance**.  \n",
    "3. Influence of the **C** coefficient toward **classification performance** among different **kernels**.  \n",
    "4. Influence of the **gamma** coefficient toward **classification performance** among different **kernels**.  \n",
    "5. Influence of the **C** and **gamma** coefficients toward **classification performance**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing as mp\n",
    "from copy import deepcopy\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.nbits = 2048\n",
    "args.n_splits = 5\n",
    "args.test_size = 0.2\n",
    "args.batch_size=128\n",
    "args.shuffle = True\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "list_tox_type = ['nr-ahr', 'nr-ar-lbd', \n",
    "                 'nr-ar', 'nr-aromatase', \n",
    "                 'nr-er-lbd', 'nr-er', \n",
    "                 'nr-ppar-gamma', 'sr-are', \n",
    "                 'sr-atad5', 'sr-hse', \n",
    "                 'sr-mmp', 'sr-p53']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset by Generating Molecular Fingerprints  \n",
    "\n",
    "Since the molecular information is provided within **smile** string form, we need to convert this strings into fixed-dimension feature vector. \n",
    "For this purpose, a **Morgan Fingerprints** methods was very suitable as it produces fixed-size vector with given dimension while capturing chemical information as well.  \n",
    "\n",
    "You can produce fingerprint with specified dimension with arguments **nBits**  \n",
    "Also, there are some **smile** string which cannot be converted into fingerprints so we excluded them during dataset preparation.  \n",
    "\n",
    "`RDkit` Fingerprint Ref : http://www.rdkit.org/docs/GettingStartedInPython.html#morgan-fingerprints-circular-fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_partition = dict()\n",
    "for tox_type in list_tox_type:\n",
    "    args.tox_type = tox_type\n",
    "    X, y = make_dataset(args)\n",
    "    list_partition = make_partition(X, y, args)\n",
    "    dict_partition[args.tox_type] = list_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'train': <utils.myDataset object at 0x7f8ca3665b00>, 'val': <utils.myDataset object at 0x7f8ca3665978>, 'test': <utils.myDataset object at 0x7f8ca3665ac8>}]\n"
     ]
    }
   ],
   "source": [
    "print(dict_partition['nr-ahr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary saves experiment results with their hyperparatemr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model Architecture Define\n",
    "\n",
    "The structure of the MLP mainly consists of linear layer, ReLU activation layer and dropout layer.  \n",
    "At the end of the model, a sigmoid layer is adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(args):\n",
    "    list_module = list()\n",
    "    list_module += [nn.Linear(args.input_dim, args.hidden_dim), nn.ReLU()]\n",
    "\n",
    "    if args.n_layer-2 > 2:\n",
    "        for _ in range(args.n_layer-2):\n",
    "            list_module.append(nn.Linear(hidden_dim))\n",
    "            list_module.append(nn.ReLU())\n",
    "            if args.dropout_rate > 0:\n",
    "                list_module.append(nn.Dropout(args.dropout_rate))\n",
    "            \n",
    "    list_module.append(nn.Linear(args.hidden_dim, args.output_dim))\n",
    "    list_module.append(nn.Sigmoid())\n",
    "    \n",
    "    model = nn.Sequential(*list_module)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Test code to construct MLP classifier \\nargs.input_dim = 2048\\nargs.hidden_dim = 256\\nargs.output_dim = 1\\nargs.dropout_rate = 0.2\\nargs.n_layer = 3\\nmodel = construct_model(args)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Test code to construct MLP classifier \n",
    "args.input_dim = 2048\n",
    "args.hidden_dim = 256\n",
    "args.output_dim = 1\n",
    "args.dropout_rate = 0.2\n",
    "args.n_layer = 3\n",
    "model = construct_model(args)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Template  \n",
    "\n",
    "This section includes template code for launching individual experiments with given hyperparameters and experiment settings such as kernel type, C, gamma, fingerprint dimension, number of dataset fold and etc.  \n",
    "\n",
    "- Data synthesis for insufficient class is shown during k-folding dataset.   \n",
    "- Also, it includes function to execute each experiments in subprocess in order to maximize system resource utlization.\n",
    "- **args** object contains all the hyperparameters and experiments settings to control the experiments.  \n",
    "\n",
    "sklearn **k-fold** Ref : http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold  \n",
    "**apply_async** Ref : https://stackoverflow.com/questions/8533318/multiprocessing-pool-when-to-use-apply-apply-async-or-map  \n",
    "Using **SMOTE** Ref : https://beckernick.github.io/oversampling-modeling/  \n",
    "Using Custom **Dataset** and **DataLoader** Ref : https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, criterion, args):\n",
    "    \n",
    "    best_test_acc = 0\n",
    "    cnt_iter = 0\n",
    "    dict_train_loss = dict()\n",
    "    dict_val_loss = dict()\n",
    "    \n",
    "    data_iter = DataLoader(\n",
    "        partition['train'],\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle\n",
    "    )\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        epoch_train_loss = 0\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X, y = Variable(batch[0]), Variable(batch[1])\n",
    "            X, y = X.to(args.device).float(), y.to(args.device).float()\n",
    "            y = y.view(-1, 1)\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_y = model(X)\n",
    "            pred_y.require_grad = False\n",
    "            train_loss = criterion(pred_y, y)\n",
    "            epoch_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            cnt_iter += 1\n",
    "            \n",
    "        dict_train_loss[cnt_iter/len(data_iter)] = train_loss.item()\n",
    "        val_loss = validate(model, partition, criterion, args)\n",
    "        dict_val_loss[cnt_iter/len(data_iter)] = val_loss\n",
    "           \n",
    "    return model, pd.Series(dict_train_loss), pd.Series(dict_val_loss)\n",
    "\n",
    "def validate(model, partition, criterion, args):\n",
    "    epoch_val_loss = 0\n",
    "    model.eval()\n",
    "    data_iter = DataLoader(\n",
    "        partition['val'],\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X, y = Variable(batch[0]), Variable(batch[1])\n",
    "            X, y = X.to(args.device).float(), y.to(args.device).float()\n",
    "            y = y.view(-1, 1)\n",
    "            pred_y = model(X)\n",
    "            \n",
    "            val_loss = criterion(pred_y, y)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            \n",
    "    return epoch_val_loss / len(data_iter)\n",
    "\n",
    "def evaluate(model, partition, args):\n",
    "    model.eval()\n",
    "    data_iter = DataLoader(\n",
    "        partition['test'],\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        list_accu = list()\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X, y = Variable(batch[0]), Variable(batch[1])\n",
    "            X, y = X.to(args.device).float(), y.to(args.device).float()\n",
    "            y = y.view(-1, 1)\n",
    "\n",
    "            pred_y = model(X)\n",
    "            target = y >= 0.5\n",
    "            output = pred_y >= 0.5\n",
    "            acc = float(output.eq(target).sum()) / target.numel()\n",
    "            list_accu.append(acc)\n",
    "            \n",
    "    return np.array(list_accu).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "    model = construct_model(args)\n",
    "    model.to(args.device)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    if args.optim == 'ADAM':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, \"Undefined Optimizer Type\"\n",
    "        \n",
    "    model, sr_train_loss, sr_val_loss = train(model, partition, optimizer, criterion, args)\n",
    "    accu = evaluate(model, partition, args)\n",
    "    return accu, sr_train_loss, sr_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_experiment(list_partition, args):    \n",
    "    list_accu = list()\n",
    "    for partition in list_partition:\n",
    "        accu, str_train_loss, sr_val_loss = experiment(partition, args)\n",
    "        list_accu.append(accu)\n",
    "    return np.array(list_accu).mean(), np.array(list_accu).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subproc_experiment(args):\n",
    "    ts = time.time()\n",
    "    list_partition = args.list_partition\n",
    "    acc_mean, acc_std = kfold_experiment(list_partition, args)\n",
    "    te = time.time()\n",
    "    \n",
    "    result = {\"acc_mean\":acc_mean, \"acc_std\":acc_std, 'elapsed':te-ts}\n",
    "    temp_args = vars(args)\n",
    "#     del temp_args['dataset']\n",
    "    result.update(temp_args)\n",
    "    return result\n",
    "    \n",
    "def callback_experiment(result):\n",
    "    result = deepcopy(result)    \n",
    "    output = \"Acc Mean: {:0.3f} Acc STD: {:0.3f} Elapsed: {:3.1f}\"\n",
    "    output = output.format(result['acc_mean'],\n",
    "                           result['acc_std'],\n",
    "                           result['elapsed'])\n",
    "    print(output)\n",
    "    \n",
    "    global exp_data\n",
    "    list_experiments = exp_data.get(args.exp_name, [])\n",
    "    list_experiments.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.input_dim = 2048\n",
    "args.hidden_dim = 128\n",
    "args.output_dim = 1\n",
    "args.n_layer = 2\n",
    "args.dropout_rate = 0.2\n",
    "args.lr = 0.01\n",
    "args.l2_coef = 0\n",
    "args.optim = 'ADAM'\n",
    "args.epoch = 30\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "list_partition = dict_partition['nr-ahr']\n",
    "accu = kfold_experiment(list_partition, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiemnt1. Effect of Hidden Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, molecular fingerprints would be calculated with different nbits values. If the value of the nbits is too low, then fingerprint vector would not represent important information. Otherwise, if the value of the nbits is too high, then fingerprint vector would be sparse so that model would less capture important feature from the fingerprint vector  \n",
    "\n",
    "**Pandas Dataframe** construction Ref : http://pbpython.com/pandas-list-dict.html  \n",
    "**Linear SVC** Ref : http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html  \n",
    "**SVC** Ref : http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "args.seed = 123\n",
    "args.C = 1.0\n",
    "args.gamma = 'auto'\n",
    "args.n_splits = 5\n",
    "args.exp_name = 'exp_nbits'\n",
    "\n",
    "exp_data['exp_nbits'] = list()\n",
    "list_nbits = [1, 4, 16, 64, 256, 1024, 2048, 4096]#, 8192]\n",
    "\n",
    "pool = mp.Pool(processes=14)\n",
    "for tox_type in list_tox_type[:]:\n",
    "    for nbits in list_nbits:\n",
    "        args.tox_type = tox_type\n",
    "        args.nbits = nbits\n",
    "        pool.apply_async(subproc_experiment, args = (deepcopy(args),), callback=callback_experiment)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exp_data['exp_nbits'])\n",
    "df = df[['accu', 'roc_auc', 'nbits', 'tox_type']]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_size_inches(15, 10)\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "grid = sns.lineplot(x=\"nbits\", y=\"accu\", hue=\"tox_type\", markers=True, data=df, ax=ax[0][0])\n",
    "grid.set_title(\"Accuracy vs nbits\")\n",
    "grid.set(xscale=\"log\")\n",
    "grid.grid(True)\n",
    "\n",
    "grid = sns.lineplot(x=\"nbits\", y=\"roc_auc\", hue=\"tox_type\", data=df, ax=ax[0][1])\n",
    "grid.set_title(\"ROC-AUC vs nbits\")\n",
    "grid.set(xscale=\"log\")\n",
    "grid.grid(True)\n",
    "\n",
    "df_accu = df.pivot(index='tox_type', columns='nbits', values='accu')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[1][0])\n",
    "grid.set_title(\"Binary Classification Accuracy\")\n",
    "\n",
    "df_roc_auc = df.pivot(index='tox_type', columns='nbits', values='roc_auc')\n",
    "grid = sns.heatmap(df_roc_auc, annot=True, ax=ax[1][1])\n",
    "grid.set_title(\"ROC-AUC\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion  \n",
    "\n",
    "Above figures shows accuracy and roc-auc value change over dimension of the fingerprints.  \n",
    "The figures in the upper row are plotted with line-chart to deliver the tendency among variables.  \n",
    "The figures in the lower row are plotted with heatmap to deliver exact accuracy and roc-auc value.  \n",
    "\n",
    "**Experiment Settings.**   \n",
    "- Tested dimensions were [1, 4, 16, 64, 256, 1024, 2048, 4096] and higher dimensions were not tested since it took long computation time.  \n",
    "- All 12 toxicity types were tested in order to observe the general effect of vector size.  \n",
    "- A linear kernel was used due to its superior computation speed. C and gamma value were selected as 1.0 and 1/n_feature, respectively. \n",
    "- All results were derived from the 5-fold valdiation process  \n",
    "\n",
    "**Notable Results.**    \n",
    "- Both accuracy and roc-auc are increased while the dimension of the fingerprints increase. \n",
    "- When vector size is 1 and 4, auc-roc is almost 0.5 which means that the classifier cannot distinguish the input which is reasonable result since too many information are condensed into just few elements.  \n",
    "- It is notable that accuracy and roc-auc were around 0.9 when vector size is more than 2048 without any hyperparameter optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment2. Effect of Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "args.nbits = 64\n",
    "args.seed = 123\n",
    "args.C = 1.0\n",
    "args.gamma = 'auto'\n",
    "args.n_splits = 5\n",
    "args.exp_name = 'exp_kernel'\n",
    "\n",
    "exp_data['exp_kernel'] = list()\n",
    "list_kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "pool = mp.Pool(processes=14)\n",
    "for tox_type in list_tox_type[:]:\n",
    "    for kernel in list_kernel:\n",
    "        args.tox_type = tox_type\n",
    "        args.kernel = kernel\n",
    "        pool.apply_async(subproc_experiment, args = (deepcopy(args),), \n",
    "                         callback=callback_experiment)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exp_data['exp_kernel'])\n",
    "df = df[['accu', 'roc_auc', 'kernel', 'tox_type']]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_size_inches(15, 10)\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "grid = sns.lineplot(x=\"kernel\", y=\"accu\", hue=\"tox_type\", markers=True, data=df, ax=ax[0][0])\n",
    "grid.set_title(\"Accuracy vs kernel\")\n",
    "grid.grid(True)\n",
    "\n",
    "grid = sns.lineplot(x=\"kernel\", y=\"roc_auc\", hue=\"tox_type\", data=df, ax=ax[0][1])\n",
    "grid.set_title(\"ROC-AUC vs kernel\")\n",
    "grid.grid(True)\n",
    "\n",
    "df_accu = df.pivot(index='tox_type', columns='kernel', values='accu')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[1][0])\n",
    "grid.set_title(\"Binary Classification Accuracy\")\n",
    "\n",
    "df_roc_auc = df.pivot(index='tox_type', columns='kernel', values='roc_auc')\n",
    "grid = sns.heatmap(df_roc_auc, annot=True, ax=ax[1][1])\n",
    "grid.set_title(\"ROC-AUC\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion  \n",
    "\n",
    "Above figures shows accuracy and roc-auc value change over type of the kernel.  \n",
    "The figures in the upper row are plotted with line-chart to deliver the tendency among variables.  \n",
    "The figures in the lower row are plotted with heatmap to deliver exact accuracy and roc-auc value.  \n",
    "\n",
    "**Experiment Settings.**  \n",
    "- Tested kernel were ['linear', 'poly', 'rbf', 'sigmoid'].  \n",
    "- All 12 toxicity types were tested in order to observe the general effect of kernel type.  \n",
    "- 64 dimension was selected for the fingerprint vector size in order to reduce the experiment time.  \n",
    "- Default C and gamma value were selected as 1.0 and 1/n_feature, respectively. \n",
    "- All results were derived from the 5-fold valdiation process  \n",
    "\n",
    "**Notable Results.**  \n",
    "- The performance of accuracy and roc-auc were decreased in order of 'rbf' > 'poly' > 'linear' > 'sigmoid'. \n",
    "- The order of the performance among different tox_type was almost consisent aganist the kernel type that it might  imply each tox_type dataset has it own data complexity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment3. Effect of 'C' coef of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "args.nbits = 64\n",
    "args.seed = 123\n",
    "args.gamma = 'auto'\n",
    "args.n_splits = 5\n",
    "args.kernel = 'poly'\n",
    "args.exp_name = 'exp_C'\n",
    "args.tox_type = 'nr-ahr'\n",
    "\n",
    "exp_data['exp_C'] = list()\n",
    "list_C = [ i for i in range(1, 40, 3)]\n",
    "list_kernel = ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "\n",
    "pool = mp.Pool(processes=14)\n",
    "for kernel in list_kernel[:]:\n",
    "    for C in list_C:\n",
    "        args.kernel = kernel\n",
    "        args.C = C\n",
    "        pool.apply_async(subproc_experiment, \n",
    "                         args = (deepcopy(args),), \n",
    "                         callback=callback_experiment)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exp_data['exp_C'])\n",
    "df = df[['accu', 'roc_auc', 'C', 'kernel', 'elapsed']]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "grid = sns.lineplot(x=\"C\", y=\"accu\", hue=\"kernel\", markers=True, data=df, ax=ax[0][0])\n",
    "grid.set_title(\"Accuracy vs C\")\n",
    "grid.grid(True)\n",
    "\n",
    "grid = sns.lineplot(x=\"C\", y=\"roc_auc\", hue=\"kernel\", data=df, ax=ax[0][1])\n",
    "grid.set_title(\"ROC-AUC vs C\")\n",
    "grid.grid(True)\n",
    "\n",
    "df_accu = df.pivot(index='kernel', columns='C', values='accu')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[1][0])\n",
    "grid.set_title(\"Binary Classification Accuracy\")\n",
    "\n",
    "df_roc_auc = df.pivot(index='kernel', columns='C', values='roc_auc')\n",
    "grid = sns.heatmap(df_roc_auc, annot=True, ax=ax[1][1])\n",
    "grid.set_title(\"ROC-AUC\")\n",
    "\n",
    "df_accu = df.pivot(index='kernel', columns='C', values='elapsed')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[2][0], cmap='jet')\n",
    "grid.set_title(\"Elapsed Time (sec)\")\n",
    "\n",
    "ax[-1, -1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion  \n",
    "\n",
    "Above figures shows accuracy and roc-auc value change over C value.  \n",
    "The figures in the upper row are plotted with line-chart to deliver the tendency among variables.  \n",
    "The figures in the middel row are plotted with heatmap to deliver exact accuracy and roc-auc value.  \n",
    "The figure in the lower row is plotted with heatmap to deliver execution time.  \n",
    "\n",
    "**Experiment Settings.**  \n",
    "- Tested C values were [1,4,7,10,13,16,19,22,25,28,31,34,37].  \n",
    "- 4 kernel types: ['linear', 'poly', 'rbf', 'sigmoid'] were tested in order to observe the general effect of C towrad a kernel type.  \n",
    "- 64 dimension was selected for the fingerprint vector size in order to reduce the experiment time.  \n",
    "- Default gamma value was selected as 1/n_feature. \n",
    "- Only tested with 'nr-ahr' tox_type. \n",
    "- All results were derived from the 5-fold valdiation process  \n",
    "\n",
    "**Notable Results.**  \n",
    "- In 'poly' and 'rbf' the performance of accuracy and roc-auc were increased with C value. \n",
    "- On the other hands, in 'sigmoid', 'linear' the accuracy was unstable with C value.  \n",
    "- In 'sigmoid', 'linear' the roc-auc seems decreased with C value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment4. Effect of 'gamma' coef of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "args.nbits = 64\n",
    "args.seed = 123\n",
    "args.C = 1.0\n",
    "args.n_splits = 5\n",
    "args.exp_name = 'exp_gamma'\n",
    "args.tox_type = 'nr-ahr'\n",
    "\n",
    "exp_data['exp_gamma'] = list()\n",
    "list_gamma = [ 10**i for i in range(-4, 5)]\n",
    "list_kernel = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "pool = mp.Pool(processes=14)\n",
    "for kernel in list_kernel[:]:\n",
    "    for gamma in list_gamma:\n",
    "        args.kernel = kernel\n",
    "        args.gamma = gamma\n",
    "        pool.apply_async(subproc_experiment, \n",
    "                         args = (deepcopy(args),), \n",
    "                         callback=callback_experiment)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exp_data['exp_gamma'])\n",
    "df = df[['accu', 'roc_auc', 'gamma', 'kernel', 'elapsed']]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "grid = sns.lineplot(x=\"gamma\", y=\"accu\", hue=\"kernel\", markers=True, data=df, ax=ax[0][0])\n",
    "grid.set_title(\"Accuracy vs gamma\")\n",
    "grid.grid(True)\n",
    "grid.set(xscale=\"log\")\n",
    "\n",
    "grid = sns.lineplot(x=\"gamma\", y=\"roc_auc\", hue=\"kernel\", data=df, ax=ax[0][1])\n",
    "grid.set_title(\"ROC-AUC vs gamma\")\n",
    "grid.grid(True)\n",
    "grid.set(xscale=\"log\")\n",
    "\n",
    "df_accu = df.pivot(index='kernel', columns='gamma', values='accu')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[1][0])\n",
    "grid.set_title(\"Binary Classification Accuracy\")\n",
    "\n",
    "df_roc_auc = df.pivot(index='kernel', columns='gamma', values='roc_auc')\n",
    "grid = sns.heatmap(df_roc_auc, annot=True, ax=ax[1][1])\n",
    "grid.set_title(\"ROC-AUC\")\n",
    "\n",
    "df_accu = df.pivot(index='kernel', columns='gamma', values='elapsed')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[2][0], cmap='jet')\n",
    "grid.set_title(\"Elapsed Time (sec)\")\n",
    "\n",
    "ax[-1, -1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion  \n",
    "\n",
    "Above figures shows accuracy and roc-auc value change over gamma value.  \n",
    "The figures in the upper row are plotted with line-chart to deliver the tendency among variables.  \n",
    "The figures in the middel row are plotted with heatmap to deliver exact accuracy and roc-auc value.  \n",
    "The figure in the lower row is plotted with heatmap to deliver execution time.  \n",
    "\n",
    "**Experiment Settings.**  \n",
    "- Tested C values were 10^[-4, -3, -2, -1, 0, 1, 2, 3, 4].  \n",
    "- 3 kernel types: ['poly', 'rbf', 'sigmoid'] were tested in order to observe the general effect of gamma towrad a kernel type('linear' was excluded since it does not have gamma parameter).  \n",
    "- 64 dimension was selected for the fingerprint vector size in order to reduce the experiment time.  \n",
    "- Default C value was selected as 1.0. \n",
    "- Only tested with 'nr-ahr' tox_type. \n",
    "- All results were derived from the 5-fold valdiation process  \n",
    "\n",
    "**Notable Results.**  \n",
    "- Overally, there were some interval of the gamma value where the performance is maximized for each kernel type.  \n",
    "- For example, 'poly' and 'rbf' were maximized around 0.1~10.0 and 'sigmoid' was maximized around 0.01.  \n",
    "- 'sigmoid' was worst kernel type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment5. Simultaneous Effect of 'gamma' and 'C' coef of SVC\n",
    "\n",
    "Gamma and C Ref : http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "args.nbits = 64\n",
    "args.seed = 123\n",
    "args.C = 1.0\n",
    "args.n_splits = 5\n",
    "args.exp_name = 'exp_c_gamma'\n",
    "args.tox_type = 'nr-ahr'\n",
    "args.kernel = 'rbf'\n",
    "\n",
    "exp_data['exp_c_gamma'] = list()\n",
    "list_C = [ 4**i for i in range(-4, 4)]\n",
    "list_gamma = [ 5**i for i in range(-3, 4)]\n",
    "print(\"Total {} Cases\".format(len(list_C)*len(list_gamma)))\n",
    "\n",
    "pool = mp.Pool(processes=14)\n",
    "for C in list_C[:]:\n",
    "    for gamma in list_gamma:\n",
    "        args.C = C\n",
    "        args.gamma = gamma\n",
    "        pool.apply_async(subproc_experiment, \n",
    "                         args = (deepcopy(args),), \n",
    "                         callback=callback_experiment)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exp_data['exp_c_gamma'])\n",
    "df = df[['accu', 'roc_auc', 'gamma', 'C', 'elapsed']]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "grid = sns.lineplot(x=\"C\", y=\"accu\", hue=\"gamma\", markers=True, data=df, ax=ax[0][0])\n",
    "grid.set_title(\"Accuracy vs gamma\")\n",
    "grid.grid(True)\n",
    "\n",
    "grid = sns.lineplot(x=\"C\", y=\"roc_auc\", hue=\"gamma\", data=df, ax=ax[0][1])\n",
    "grid.set_title(\"ROC-AUC vs gamma\")\n",
    "grid.grid(True)\n",
    "\n",
    "df_accu = df.pivot(index='C', columns='gamma', values='accu')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[1][0])\n",
    "grid.set_title(\"Binary Classification Accuracy\")\n",
    "\n",
    "df_roc_auc = df.pivot(index='C', columns='gamma', values='roc_auc')\n",
    "grid = sns.heatmap(df_roc_auc, annot=True, ax=ax[1][1])\n",
    "grid.set_title(\"ROC-AUC\")\n",
    "\n",
    "df_accu = df.pivot(index='C', columns='gamma', values='elapsed')\n",
    "grid = sns.heatmap(df_accu, annot=True, ax=ax[2][0], cmap='jet')\n",
    "grid.set_title(\"Elapsed Time (sec)\")\n",
    "\n",
    "ax[-1, -1].axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Discussion  \n",
    "\n",
    "Above figures shows accuracy and roc-auc value change over gamma and C value.  \n",
    "The figures in the upper row are plotted with line-chart to deliver the tendency among variables.  \n",
    "The figures in the middel row are plotted with heatmap to deliver exact accuracy and roc-auc value.  \n",
    "The figure in the lower row is plotted with heatmap to deliver execution time.  \n",
    "\n",
    "**Experiment Settings.**\n",
    "- Tested C values were 4^[-4, -3, -2, -1, 0, 1, 2, 3].  \n",
    "- Tested gamma values were 5^[-3, -2, -1, 0, 1, 2, 3].\n",
    "- Best performing 'rbf' kernel was selected.  \n",
    "- 64 dimension was selected for the fingerprint vector size in order to reduce the experiment time.  \n",
    "- Only tested with 'nr-ahr' tox_type. \n",
    "- All results were derived from the 5-fold valdiation process  \n",
    "\n",
    "**Notable Results.**  \n",
    "- It is worth to pay attention to the figures in the middle row. There are **highlighted** area with in the middle of the heatmap.\n",
    "- It is observable that accuracy is maximized at C: 1.0~4.0 and gamma: 0.2~25.0 and the roc-auc is maximized at C: 0.0625~0.25 and gamma: 0.2~1.0.    \n",
    "- Suprisingly, the model achieves 96% on binary classification with 0.96 roc-auc area value with only 64 dimension finger prints with hyperparameter grid searching!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Improvements\n",
    "\n",
    "1. Fine tune the model with Hyperparameter Searching Tool.   \n",
    "2. Increase the dimension of the fingerprints to encode sufficient information.  \n",
    "3. Applying different data augumentation method except SMOTE.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
