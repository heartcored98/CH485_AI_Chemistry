{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f69c4cb6fb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "import json\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from utils import *\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.nbits = 2048\n",
    "args.n_splits = 5\n",
    "args.test_size = 0.2\n",
    "args.num_mol = 50000\n",
    "args.max_len = 120\n",
    "args.shuffle = True\n",
    "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "args.optim = 'RMSProp'\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_partition = make_partition(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create char_to_ix Ref: https://github.com/pytorch/tutorials/blob/master/beginner_source/nlp/word_embeddings_tutorial.py  \n",
    "Pre-defined Embedding Layer Ref: https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76  \n",
    "ResNet Variation Ref: https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(filename='../Data/logP/vocab.npy'):\n",
    "    vocab = np.load(filename)\n",
    "    vocab_size = len(vocab)\n",
    "    char_to_ix = {char: i for i, char in enumerate(vocab)}\n",
    "    return vocab, char_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_filter, out_filter, stride, use_bn, dp_rate, block_type):\n",
    "        super(ResBlock, self).__init__()   \n",
    "        self.use_bn = use_bn\n",
    "        self.block_type = block_type\n",
    "        self.conv1 = nn.Conv2d(in_filter, out_filter, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(out_filter, out_filter, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(out_filter)\n",
    "        self.bn2 = nn.BatchNorm2d(out_filter)\n",
    "        self.dropout = nn.Dropout2d(dp_rate)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_filter != out_filter:\n",
    "            self.shortcut.add_module(\n",
    "                'conv', nn.Conv2d(in_filter, out_filter,\n",
    "                                  kernel_size=1, stride=stride, \n",
    "                                  padding=0, bias=False)\n",
    "            )\n",
    "        \n",
    "    def forward(self, _x):\n",
    "        if self.block_type == 'a': #original residual block\n",
    "            x = self.relu(self.bn1(self.conv1(_x))) if self.use_bn else self.relu(self.conv1(_x))\n",
    "            x = self.bn2(self.conv2(x)) if self.use_bn else self.conv2(x)\n",
    "            x = x + self.shortcut(_x)\n",
    "            return self.dropout(self.relu(x))\n",
    "        \n",
    "        elif self.block_type == 'b': # BN after addition\n",
    "            x = self.relu(self.bn1(self.conv1(_x))) if self.use_bn else self.relu(self.conv1(_x))\n",
    "            x = self.conv2(x) + self.shortcut(_x)\n",
    "            return self.dropout(self.relu(self.bn2(x)) if self.use_bn else self.relu(x))\n",
    "        \n",
    "        elif self.block_type == 'c': # ReLU before addition\n",
    "            x = self.relu(self.bn1(self.conv1(_x))) if self.use_bn else self.relu(self.conv1(_x))\n",
    "            x = self.relu(self.bn2(self.conv2(x))) if self.use_bn else self.relu(self.conv2(x))\n",
    "            return self.dropout(x + self.shortcut(_x))\n",
    "        \n",
    "        elif self.block_type == 'd': # ReLU-only pre-activation\n",
    "            x = self.bn1(self.conv1(self.relu(_x))) if self.use_bn else self.conv1(self.relu(_x))\n",
    "            x = self.bn2(self.conv2(self.relu(x))) if self.use_bn else self.conv2(self.relu(x))\n",
    "            return self.dropout(x + self.shortcut(_x))\n",
    "        \n",
    "        elif self.block_type == 'e': # full pre-activation\n",
    "            x = self.conv1(self.relu(self.bn1(_x))) if self.use_bn else self.conv1(self.relu(_x))\n",
    "            x = self.conv2(self.relu(self.bn2(x))) if self.use_bn else self.conv2(self.relu(x))\n",
    "            return self.dropout(x + self.shortcut(_x))\n",
    "             \n",
    "            \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Net, self).__init__()   \n",
    "        \n",
    "        # Create Atom Element embedding layer\n",
    "        self.embedding = self.create_emb_layer(args.vocab_size, args.emb_train)\n",
    "        \n",
    "        # Create Residual Convolution layer\n",
    "        list_res_blocks = list()\n",
    "        n_channel = 1\n",
    "        for i in range(args.n_stage):\n",
    "            if i==0:\n",
    "                list_res_blocks.append(ResBlock(n_channel, n_channel*args.start_channel, args.stride, args.use_bn, args.dp_rate, args.block_type))\n",
    "                n_channel *= args.start_channel\n",
    "            else:\n",
    "                list_res_blocks.append(ResBlock(n_channel, n_channel*2, args.stride, args.use_bn, args.dp_rate, args.block_type))\n",
    "                n_channel *= 2\n",
    "            for j in range(args.n_layer-1):\n",
    "                list_res_blocks.append(ResBlock(n_channel, n_channel, 1, args.use_bn, args.dp_rate, args.block_type))\n",
    "        self.res_blocks = nn.Sequential(*list_res_blocks)\n",
    "        \n",
    "        # Create MLP layers\n",
    "        fc_shape = self._estimate_fc_shape((1, args.max_len,))\n",
    "#         fc_shape = (4000, 200)\n",
    "        self.fc1 = nn.Linear(fc_shape[-1], 200)\n",
    "        self.fc2 = nn.Linear(200, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._conv_forward(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.squeeze(x)\n",
    "    \n",
    "    def _conv_forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        embeds = embeds.view(embeds.shape[0], 1, embeds.shape[1], embeds.shape[2])\n",
    "        x = self.res_blocks(embeds)\n",
    "        return x\n",
    "    \n",
    "    def _estimate_fc_shape(self, input_shape):\n",
    "        dummy_input = torch.zeros(input_shape).long()\n",
    "        dummy_output = self._conv_forward(dummy_input)\n",
    "        fc_shape = dummy_output.view(dummy_output.shape[0], -1).shape\n",
    "        return fc_shape\n",
    "        \n",
    "\n",
    "    def create_emb_layer(self, vocab_size, emb_train):\n",
    "        emb_layer = nn.Embedding(vocab_size, vocab_size)\n",
    "        weight_matrix = torch.zeros((vocab_size, vocab_size))\n",
    "        for i in range(vocab_size):\n",
    "            weight_matrix[i][i] = 1\n",
    "        emb_layer.load_state_dict({'weight': weight_matrix})\n",
    "\n",
    "        if not emb_train:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "        return emb_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train, Validate, Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, partition, optimizer, criterion, char_to_ix, args, **kwargs):\n",
    "    data_iter = DataLoader(\n",
    "        partition['train'],\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=args.shuffle\n",
    "    )\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    cnt_iter = 0\n",
    "    for batch_idx, batch in enumerate(data_iter):\n",
    "        X, y = batch[0], batch[1]\n",
    "        X = torch.Tensor([[char_to_ix[c] for c in smile] for smile in X]).long()\n",
    "        X, y = X.to(args.device), y.to(args.device).float()\n",
    "    \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_y = model(X)\n",
    "        pred_y.require_grad = False\n",
    "        train_loss = criterion(pred_y, y)\n",
    "        epoch_train_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cnt_iter += 1\n",
    "        args.bar.update(len(X))\n",
    "#         break\n",
    "    return model, epoch_train_loss/cnt_iter\n",
    "\n",
    "def validate(model, partition, criterion, char_to_ix, args):\n",
    "    data_iter = DataLoader(\n",
    "        partition['val'],\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=args.shuffle\n",
    "    )\n",
    "    \n",
    "    epoch_val_loss = 0\n",
    "    cnt_iter = 0\n",
    "    for batch_idx, batch in enumerate(data_iter):\n",
    "        X, y = batch[0], batch[1]\n",
    "        X = torch.Tensor([[char_to_ix[c] for c in smile] for smile in X]).long()\n",
    "        X, y = X.to(args.device), y.to(args.device).float()\n",
    "    \n",
    "        model.eval()\n",
    "        pred_y = model(X)\n",
    "        pred_y.require_grad = False\n",
    "        val_loss = criterion(pred_y, y)\n",
    "        epoch_val_loss += val_loss.item()\n",
    "        cnt_iter += 1\n",
    "\n",
    "    return epoch_val_loss/cnt_iter\n",
    "\n",
    "def test(model, partition, char_to_ix, args, **kwargs):\n",
    "    data_iter = DataLoader(\n",
    "        partition['test'],\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    list_y, list_pred_y = list(), list()\n",
    "    for batch_idx, batch in enumerate(data_iter):\n",
    "        X, y = batch[0], batch[1]\n",
    "        X = torch.Tensor([[char_to_ix[c] for c in smile] for smile in X]).long()\n",
    "        X, y = X.to(args.device), y.to(args.device).float()\n",
    "    \n",
    "        model.eval()\n",
    "        pred_y = model(X)\n",
    "        list_y += y.cpu().detach().numpy().tolist()\n",
    "        list_pred_y += pred_y.cpu().detach().numpy().tolist()\n",
    "        args.bar.update(len(X))\n",
    "\n",
    "    mae = mean_absolute_error(list_y, list_pred_y)\n",
    "    std = np.std(np.array(list_y)-np.array(list_pred_y))\n",
    "    return mae, std, list_y, list_pred_y\n",
    "\n",
    "def experiment(partition, args):\n",
    "    ts = time.time()\n",
    "    vocab, char_to_ix = create_vocab()\n",
    "    args.vocab_size = len(vocab)\n",
    "    args.input_shape = (args.max_len, args.vocab_size)\n",
    "    model = Net(args)\n",
    "    model.to(args.device)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    trainable_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    if args.optim == 'ADAM':\n",
    "        optimizer = optim.Adam(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, \"Undefined Optimizer Type\"\n",
    "        \n",
    "    # Train, Validate, Evaluate\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_mae = list()\n",
    "    list_std = list()\n",
    "    \n",
    "    args.best_mae = 10000\n",
    "    for epoch in range(args.epoch):\n",
    "        model, train_loss = train(model, partition, optimizer, criterion, char_to_ix, args, **{'bar':bar})\n",
    "        val_loss = validate(model, partition, criterion, char_to_ix, args)\n",
    "        mae, std, true_y, pred_y = test(model, partition, char_to_ix, args, **{'bar':bar})\n",
    "\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_val_loss.append(val_loss)\n",
    "        list_mae.append(mae)\n",
    "        list_std.append(std)\n",
    "        \n",
    "        if args.best_mae > mae or epoch==0:\n",
    "            args.best_epoch = epoch\n",
    "            args.best_mae = mae\n",
    "            args.best_std = std\n",
    "            args.best_true_y = true_y\n",
    "            args.best_pred_y = pred_y\n",
    "    \n",
    "    te = time.time()\n",
    "    \n",
    "    # Logging Experiment Results\n",
    "    args.elapsed = te-ts\n",
    "    args.train_losses = list_train_loss\n",
    "    args.val_losses = list_val_loss\n",
    "    args.maes = list_mae\n",
    "    args.stds = list_std\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8066af97c9644c99bc035083793bc288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=168000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp  1] got mae: 0.433, std: 0.561 at epoch  1\n",
      "[Exp  2] got mae: 0.423, std: 0.543 at epoch  1\n",
      "[Exp  3] got mae: 0.425, std: 0.547 at epoch  1\n",
      "[Exp  4] got mae: 0.425, std: 0.548 at epoch  1\n"
     ]
    }
   ],
   "source": [
    "args.exp_name = 'exp1_layer_stage'\n",
    "args.n_layer = 2\n",
    "args.n_stage = 1\n",
    "args.lr = 0.00005\n",
    "args.l2_coef = 0\n",
    "args.optim = 'ADAM'\n",
    "args.epoch = 1\n",
    "args.batch_size=32\n",
    "args.test_batch_size=32\n",
    "args.emb_train = False\n",
    "args.start_channel = 8\n",
    "args.stride = 1\n",
    "args.use_bn = False\n",
    "args.dp_rate = 0.0\n",
    "args.block_type = 'a'\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "writer = Writer(prior_keyword=['n_layer', 'block_type', 'use_bn', 'dp_rate', 'emb_train', 'epoch', 'batch_size'])\n",
    "partition = list_partition[0]\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "list_n_layer = [1,2]#,3,4,5]\n",
    "list_n_stage = [1,2] #, 2]#,3,4,5]\n",
    "\n",
    "# Initialize num iteration, num experiment, progress bar\n",
    "n_iter = args.epoch * (len(partition['train']) + len(partition['test']))\n",
    "n_exp = len(list_n_layer)*len(list_n_stage)\n",
    "cnt_exp = 0\n",
    "bar = tqdm_notebook(total=n_exp*n_iter, file=sys.stdout, position=0)\n",
    "bar.set_description('P {:2}/{} Exp'.format(cnt_exp, n_exp))\n",
    "\n",
    "for n_layer in list_n_layer:\n",
    "    for n_stage in list_n_stage:\n",
    "        # Update hyperparameter\n",
    "        args.n_layer = n_layer\n",
    "        args.n_stage = n_stage\n",
    "        args.bar = bar\n",
    "        result = experiment(partition, args)\n",
    "        writer.write(result)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        cnt_exp += 1\n",
    "        bar.set_description('P {:2}/{} Exp'.format(cnt_exp, n_exp))\n",
    "        print('[Exp {:2}] got mae: {:2.3f}, std: {:2.3f} at epoch {:2}'.format(cnt_exp, result.best_mae, result.best_std, result.epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from decimal import Decimal\n",
    "import json \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "class Writer2():\n",
    "    \n",
    "    def __init__(self, prior_keyword=[], dir='./results'):\n",
    "        self.prior_keyword = prior_keyword\n",
    "        self.dir = dir\n",
    "        \n",
    "    def generate_hash(args):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def write(self, args, prior_keyword=None):\n",
    "        dict_args = vars(args)\n",
    "        if 'bar' in dict_args:\n",
    "            del dict_args['bar']\n",
    "        if prior_keyword:\n",
    "            self.prior_keyword = prior_keyword\n",
    "        filename = 'exp_{}'.format(args.exp_name)\n",
    "        for keyword in self.prior_keyword:\n",
    "            value = str(dict_args[keyword])\n",
    "            if value.isdigit():\n",
    "                filename += keyword + '-{:.2E}'.format(Decimal(dict_args[keyword]))\n",
    "            else:\n",
    "                filename += keyword + '-{}'.format(value)\n",
    "        filename += '.json'\n",
    "        \n",
    "        with open(self.dir+'/'+filename, 'w') as outfile:\n",
    "            json.dump(dict_args, outfile)\n",
    "            \n",
    "        \n",
    "    def read(self, exp_name=''):\n",
    "        list_result = list()\n",
    "        \n",
    "        filenames = [f for f in listdir(self.dir) if isfile(join(self.dir, f))]\n",
    "        for filename in filenames:\n",
    "            with open(join(self.dir, filename), 'r') as infile:\n",
    "                result = json.load(infile)\n",
    "                if len(exp_name) > 0:\n",
    "                    if result['exp_name'] == exp_name:\n",
    "                        list_result.append(result)\n",
    "                else:\n",
    "                    list_result.append(result)\n",
    "                        \n",
    "        return pd.DataFrame(list_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['batch_size', 'best_epoch', 'best_mae', 'best_pred_y', 'best_std',\n",
      "       'best_true_y', 'block_type', 'device', 'dp_rate', 'elapsed',\n",
      "       'emb_train', 'epoch', 'exp_name', 'input_shape', 'l2_coef', 'lr',\n",
      "       'maes', 'max_len', 'n_layer', 'n_splits', 'n_stage', 'nbits', 'num_mol',\n",
      "       'optim', 'seed', 'shuffle', 'start_channel', 'stds', 'stride',\n",
      "       'test_batch_size', 'test_size', 'train_losses', 'use_bn', 'val_losses',\n",
      "       'vocab_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "results = writer.read(exp_name='exp1_layer_stage')\n",
    "print(results.columns)\n",
    "# results = results.loc[results['epoch'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f691dfb6748>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_y = results['best_true_y'][0]\n",
    "pred_y = results['best_pred_y'][0]\n",
    "plt.scatter(true_y, pred_y)\n",
    "plt.plot(np.linspace(-4,4,100), np.linspace(-4,4,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
